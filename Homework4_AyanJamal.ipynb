{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayannj13/Data-Science/blob/main/Homework4_AyanJamal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o0M6wvVafclb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/ogut77/DataScience/master/insurance.csv\"\n",
        "df = pd.read_csv(url)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "CbamjUmFY-tK",
        "outputId": "7be14792-06ab-45f4-c094-088bfc0af4e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebf89b9d-b530-4544-a761-8e7bc1131117\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebf89b9d-b530-4544-a761-8e7bc1131117')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ebf89b9d-b530-4544-a761-8e7bc1131117 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ebf89b9d-b530-4544-a761-8e7bc1131117');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ceff536f-2df0-438f-b370-1f96077c36be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ceff536f-2df0-438f-b370-1f96077c36be')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ceff536f-2df0-438f-b370-1f96077c36be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1338,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14,\n        \"min\": 18,\n        \"max\": 64,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          21,\n          45,\n          36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"male\",\n          \"female\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"bmi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.098186911679017,\n        \"min\": 15.96,\n        \"max\": 53.13,\n        \"num_unique_values\": 548,\n        \"samples\": [\n          23.18,\n          26.885\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"children\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"smoker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"region\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"southeast\",\n          \"northeast\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"charges\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12110.011236693994,\n        \"min\": 1121.8739,\n        \"max\": 63770.42801,\n        \"num_unique_values\": 1337,\n        \"samples\": [\n          8688.85885,\n          5708.867\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Context in Insurance Data\n",
        "This dataset is often used to predict charges based on the other variables (age, sex, bmi, children, smoker, region). For example:\n",
        "\n",
        "Input Variables (X): age, sex, bmi, children, smoker, region (features used to make predictions).\n",
        "\n",
        "Output Variable (y): charges (what you’re trying to predict)."
      ],
      "metadata": {
        "id": "dYwzA6LQjQhR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Describtion of variables\n",
        "1. Age\n",
        "Description: The age of the individual (the insured person).\n",
        "Type: Numerical (integer).\n",
        "Example Values: 19, 45, 62, etc.\n",
        "Role in Insurance: Age is a key factor in determining insurance charges. Older individuals often have higher medical costs (and thus higher charges) due to increased health risks.\n",
        "2. Sex\n",
        "Description: The gender of the individual.\n",
        "Type: Categorical (text or binary).\n",
        "Example Values: \"male,\" \"female\"\n",
        "Role in Insurance: Gender can influence insurance charges because health risks and medical expenses may differ between males and females (e.g., pregnancy-related costs for females).\n",
        "3. BMI (Body Mass Index)\n",
        "Description: A measure of body fat based on height and weight (calculated as weight in kg divided by height in meters squared).\n",
        "Type: Numerical (float).\n",
        "Example Values: 25.3, 30.1, 18.5, etc.\n",
        "Role in Insurance: Higher BMI often correlates with increased health risks (e.g., obesity-related conditions like diabetes or heart disease), leading to higher insurance charges.\n",
        "4. Children\n",
        "Description: The number of children (dependents) covered under the individual’s insurance plan.\n",
        "Type: Numerical (integer).\n",
        "Example Values: 0, 1, 3, etc.\n",
        "Role in Insurance: More children can increase insurance costs slightly, as it may reflect additional healthcare needs, though the effect is often less pronounced than other factors like smoking or age.\n",
        "5. Smoker\n",
        "Description: Indicates whether the individual smokes tobacco.\n",
        "Type: Categorical (text or binary).\n",
        "Example Values: \"yes,\" \"no\" .\n",
        "Role in Insurance: Smoking is a major factor in insurance charges. Smokers typically have much higher medical costs due to risks like lung disease or cancer, so their charges are significantly elevated.\n",
        "6. Region\n",
        "Description: The geographic region where the individual lives.\n",
        "Type: Categorical (text).\n",
        "Example Values: \"northeast,\" \"southeast,\" \"southwest,\" \"northwest\" (common in U.S.-based datasets).\n",
        "Role in Insurance: Charges can vary by region due to differences in healthcare costs, lifestyle factors, or local insurance regulations.\n",
        "7. Charges\n",
        "Description: The insurance charges (or premiums/costs) billed to the individual, typically in a currency like USD.\n",
        "Type: Numerical (float).\n",
        "Example Values: 1684.52, 11234.89, 32050.23, etc.\n",
        "Role in Insurance: This is usually the target variable (output) in predictive modeling. It represents the amount the insurance company charges, influenced by all the other columns (age, sex, BMI, etc.).\n",
        "\n"
      ],
      "metadata": {
        "id": "9fya2Ad-i8yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Check if there is null value in dataset df (5 pt)\n",
        "\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "KkwJgK18ZQMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3fad5b3-1e35-4ade-b1fb-e82d3544142e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age         0\n",
            "sex         0\n",
            "bmi         0\n",
            "children    0\n",
            "smoker      0\n",
            "region      0\n",
            "charges     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Assign charges to y  and others to X using df. y is output variable and X is input variables (5 pt)\n",
        "y = df['charges']\n",
        "\n",
        "X = df.drop('charges', axis=1)"
      ],
      "metadata": {
        "id": "7XfDiXfTZnpk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. Use  get_dummies() function from the pandas library to convert categorical variables in a DataFrame (X).\n",
        "# Drop first drops the first category’s dummy variable to avoid multicollinearity (5 pt)\n",
        "\n",
        "X = pd.get_dummies(X, drop_first=True)\n"
      ],
      "metadata": {
        "id": "e5djdXCnhxpy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Use following methods for the evaluation on test and train data\n",
        "def evalmetric(y,ypred):\n",
        " from scipy.stats import pearsonr\n",
        " import numpy as np\n",
        " e = y - ypred\n",
        " mse_f = np.mean(e**2)\n",
        " rmse_f = np.sqrt(mse_f)\n",
        " mae_f = np.mean(abs(e))\n",
        " mape_f = 100*np.mean(abs(e/y))\n",
        " crl, _ = pearsonr(y, ypred)\n",
        " r2_f = crl*crl\n",
        " print(\"MSE:\", mse_f)\n",
        " print(\"RMSE:\", rmse_f)\n",
        " print(\"MAE:\",mae_f)\n",
        " print(\"MAPE:\",mape_f)\n",
        " print(\"R-Squared:\", round(r2_f, 4))\n"
      ],
      "metadata": {
        "id": "UoTK1j0psi0-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#4.Get the correlation between X variables and y variables.(5 pt)\n",
        "\n",
        "df_corr = pd.concat([X, y], axis=1)\n",
        "\n",
        "correlation_matrix = df_corr.corr()\n",
        "\n",
        "print(correlation_matrix['charges'].sort_values(ascending=False))"
      ],
      "metadata": {
        "id": "37xaAIN_nNqq",
        "outputId": "9b95151c-776f-465a-9954-9b242fe05393",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "charges             1.000000\n",
            "smoker_yes          0.787251\n",
            "age                 0.299008\n",
            "bmi                 0.198341\n",
            "region_southeast    0.073982\n",
            "children            0.067998\n",
            "sex_male            0.057292\n",
            "region_northwest   -0.039905\n",
            "region_southwest   -0.043210\n",
            "Name: charges, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5.Split a dataset into 25%  of data as test data  and 75% of data as training data ( pt)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n"
      ],
      "metadata": {
        "id": "Tqgr4WFjnViT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Using Decision Tree and Linear Regression methods, compare the performance results on both test and training data\n",
        "#to determine which one is more likely to overfit and which is more likely to underfit.\n",
        "# Do you think that Lasso and Ridge regularization are more likely to improve the results of Linear model test data,\n",
        "# or would Random Forest or Boosting methods are more likely to improve the results of Decison tree test data?\n",
        "#Explain your reasoning.(35 pt)"
      ],
      "metadata": {
        "id": "1gm6bNy8neAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Linear regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#training the model\n",
        "lr_model = LinearRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# predictions\n",
        "y_train_pred_lr = lr_model.predict(X_train)\n",
        "y_test_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "# evaluation\n",
        "print(\"Linear Regression - Train Data:\")\n",
        "evalmetric(y_train, y_train_pred_lr)\n",
        "\n",
        "print(\"\\nLinear Regression - Test Data:\")\n",
        "evalmetric(y_test, y_test_pred_lr)\n"
      ],
      "metadata": {
        "id": "focBm-gxoDr5",
        "outputId": "4798ba39-9fbd-42ac-c11e-1d302c686678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression - Train Data:\n",
            "MSE: 37004502.18409475\n",
            "RMSE: 6083.132596294014\n",
            "MAE: 4183.153367011969\n",
            "MAPE: 42.26867490005659\n",
            "R-Squared: 0.745\n",
            "\n",
            "Linear Regression - Test Data:\n",
            "MSE: 35117755.73613632\n",
            "RMSE: 5926.023602394469\n",
            "MAE: 4243.654116653137\n",
            "MAPE: 44.468185116980976\n",
            "R-Squared: 0.7676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#decision tree\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "# train the model\n",
        "dt_model = DecisionTreeRegressor(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# predictions\n",
        "y_train_pred_dt = dt_model.predict(X_train)\n",
        "y_test_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "# evaluation\n",
        "print(\"Decision Tree - Train Data:\")\n",
        "evalmetric(y_train, y_train_pred_dt)\n",
        "\n",
        "print(\"\\nDecision Tree - Test Data:\")\n",
        "evalmetric(y_test, y_test_pred_dt)\n"
      ],
      "metadata": {
        "id": "loFZ5-CqoWYg",
        "outputId": "1f6656d3-dc9d-42c6-c0fd-7cb96b85ad85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree - Train Data:\n",
            "MSE: 182648.17106092346\n",
            "RMSE: 427.37357318969015\n",
            "MAE: 19.084122482552342\n",
            "MAPE: 0.47775094523744194\n",
            "R-Squared: 0.9987\n",
            "\n",
            "Decision Tree - Test Data:\n",
            "MSE: 36580230.16400095\n",
            "RMSE: 6048.159237652473\n",
            "MAE: 2693.294304847761\n",
            "MAPE: 29.869257985320623\n",
            "R-Squared: 0.7805\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Answers to 6th task:"
      ],
      "metadata": {
        "id": "COmYll2osdU7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Which model overfits and which underfits?**\n",
        "Decision Tree is overfitting because its train R-squared is 0.9987 which is almost perfect, but test R-squared drops to 0.7805. This shows there is huge performance gap! It memorized the training data but it struggles on unseen data when it tries to make predictions.\n",
        "\n",
        "However, Linear Regression is more balanced as its train R-squared is 0.745, and test R-squared is 0.7676. Train and test scores are close, which means the model generalizes better but it may not capture complex relationships.\n",
        "\n",
        "**2) Which method is better to improve each model?**\n",
        "\n",
        "**For Linear Regression → Lasso/Ridge**\n",
        "\n",
        "Lasso and Ridge regression can help improve Linear Regression by reducing underfitting. They do this by shrinking the importance of less significant features. But, since the train and test scores for Linear Regression are already quite close, the improvement will likely be small.\n",
        "\n",
        "**For Decision Tree → Random Forest / Boosting**\n",
        "\n",
        "For the Decision Tree model, the best way to improve test performance is to use Random Forest or Boosting methods. Random Forest helps by combining multiple trees, and this makes the model more stable and reduces overfitting. Boosting methods, such as XGBoost, or Catboost improve accuracy by focusing on the mistakes made in previous steps. These techniques will improve the Decision Tree model more than regularization would help the Linear Regression model.\n"
      ],
      "metadata": {
        "id": "GNu2KXiEo9QT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Explain performance of linear regressin on test data\n",
        "# using  Root mean squared error, mean absolute error, mean absolute percentage error and R2 metric (10 pt)\n"
      ],
      "metadata": {
        "id": "ru5josYAR_gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7th question answer:**\n",
        "Linear Regression performs moderately well on test data.\n",
        "\n",
        "The performance of Linear Regression on the test data can be explained using these metrics:\n",
        "\n",
        "**Root Mean Squared Error (RMSE):** 5926.02\n",
        "This means, the model’s predictions have an average error of about $5926. RMSE gives more weight to larger errors, so it highlights bigger mistakes.\n",
        "\n",
        "**Mean Absolute Error (MAE):** 4243.65\n",
        "This shows the average error size, meaning have an average error of about $4243.\n",
        "\n",
        "**Mean Absolute Percentage Error (MAPE)**: 44.47%\n",
        "This means the average prediction mistake is about by about 44% of the actual charges. This is quite a high error rate.\n",
        "\n",
        "**R-Squared (R²):** 0.7676\n",
        "This means the model can explain about 76.76% of the changes in insurance charges. This is a fairly good result, but it also shows that the model misses some important factors that affect the charges.\n",
        "\n",
        "In general, Linear Regression explains a good part of the data, but its errors (RMSE, MAE, and MAPE) are quite large which shows the model is not fully accurate and it may be too simple to capture all important relationships in the data."
      ],
      "metadata": {
        "id": "mkAyG1gouwZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#8. Use Random Forest and Boosting methods (XGBoost, LightGBM, and CatBoost)\n",
        "#to obtain the evaluation scores on  test data.\n",
        "#Which Boosting technique yielded the best performance on the test data based on the R² metric?\n",
        "#Did you achieve a better result compared to Random Forest on the test data based on the R² metric?\n",
        "#If there is improvement on Random forest or boosting methods over decison tree, explain  (30 pt)"
      ],
      "metadata": {
        "id": "4g6E7l-hqPjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#8th task Random forest\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# predict on test data\n",
        "y_test_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "print(\"Random Forest - Test Data:\")\n",
        "evalmetric(y_test, y_test_pred_rf)\n"
      ],
      "metadata": {
        "id": "hZGAELeHxg2i",
        "outputId": "d2530f4f-698a-48e2-c050-6d6807a1b213",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest - Test Data:\n",
            "MSE: 23114410.14038345\n",
            "RMSE: 4807.7448081593775\n",
            "MAE: 2653.61478095801\n",
            "MAPE: 30.27386314379988\n",
            "R-Squared: 0.8506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8th task xgboost\n",
        "from xgboost import XGBRegressor\n",
        "xgb_model = XGBRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# predict on test data\n",
        "y_test_pred_xgb = xgb_model.predict(X_test)\n",
        "\n",
        "print(\"XGBoost - Test Data:\")\n",
        "evalmetric(y_test, y_test_pred_xgb)\n"
      ],
      "metadata": {
        "id": "Fo-4y01uxn6C",
        "outputId": "198c8eaa-054b-48a0-a982-1399b609ae29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBoost - Test Data:\n",
            "MSE: 26433443.13176504\n",
            "RMSE: 5141.346431798293\n",
            "MAE: 2957.213261792119\n",
            "MAPE: 34.57266690344694\n",
            "R-Squared: 0.8301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8th task lightgbm\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "lgbm_model = LGBMRegressor(n_estimators=100, random_state=42)\n",
        "lgbm_model.fit(X_train, y_train)\n",
        "\n",
        "# predict on test data\n",
        "y_test_pred_lgbm = lgbm_model.predict(X_test)\n",
        "\n",
        "print(\"LightGBM - Test Data:\")\n",
        "evalmetric(y_test, y_test_pred_lgbm)\n"
      ],
      "metadata": {
        "id": "mIoalnT3xzzq",
        "outputId": "450ec86d-d1e9-4a4e-ed02-866ba06dd834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001133 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 319\n",
            "[LightGBM] [Info] Number of data points in the train set: 1003, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score 13267.935814\n",
            "LightGBM - Test Data:\n",
            "MSE: 22005117.949021608\n",
            "RMSE: 4690.961303296117\n",
            "MAE: 2700.720352413941\n",
            "MAPE: 33.101463593940274\n",
            "R-Squared: 0.8553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8th task catboost\n",
        "!pip install catboost\n"
      ],
      "metadata": {
        "id": "CnJUqdrox7JJ",
        "outputId": "5ab1fc5b-7831-4713-bcfe-1bd2e6aba012",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.7-cp311-cp311-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#catboost\n",
        "from catboost import CatBoostRegressor\n",
        "cat_model = CatBoostRegressor(n_estimators=100, verbose=0, random_state=42)\n",
        "\n",
        "cat_model.fit(X_train, y_train)\n",
        "\n",
        "#predict on test data\n",
        "y_test_pred_cat = cat_model.predict(X_test)\n",
        "\n",
        "print(\"CatBoost - Test Data:\")\n",
        "evalmetric(y_test, y_test_pred_cat)\n"
      ],
      "metadata": {
        "id": "rnzgw2vdyP9H",
        "outputId": "d4624416-722a-4542-e885-8c766f5a2431",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CatBoost - Test Data:\n",
            "MSE: 21964464.736067303\n",
            "RMSE: 4686.626157063021\n",
            "MAE: 2667.445931179085\n",
            "MAPE: 31.719396003541583\n",
            "R-Squared: 0.855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8th task questions' answers:**\n",
        "\n",
        "**1) Which Boosting technique yielded the best performance on the test data based on the R² metric?**\n",
        "\n",
        "The best Boosting method is LightGBM, because its R-squared score is 0.8553, which is the highest R-squared score out of all the boosting methods I've tried (XGBoost, LightGBM, and CatBoost).\n",
        "\n",
        "**2) Did you achieve a better result compared to Random Forest on the test data based on the R² metric?**\n",
        "\n",
        "Yes, LightGBM got an R-squared of 0.8553, which is slightly better than Random Forest with R-squared of 0.8506. The difference is quite small, but LightGBM still performed better.\n",
        "\n",
        "**3) If there is improvement on Random forest or boosting methods over decison tree, explain**\n",
        "\n",
        "Yes, all of the **ensemble methods** (Random Forest, XGBoost, LightGBM, CatBoost) did better than the single Decision Tree.\n",
        "The Decision Tree had R-squared of 0.7805 on the test data, which is much lower than all the other methods.\n",
        "\n",
        "The reason is because a single Decision Tree easily overfits to the training data. It memorizes the training set instead of learning general patterns, so it cannot generalize well on the test data.\n",
        "\n",
        "Random Forest fixes this issue by combining many trees together, which reduces overfitting.\n",
        "\n",
        "Boosting methods (like LightGBM, XGBoost, and CatBoost) build trees step by step, and each tree focuses on fixing the mistakes made by the tree before it. This helps them learn better patterns and generalize better to new data.\n",
        "That’s why these methods performed better than the single Decision Tree."
      ],
      "metadata": {
        "id": "WFmaMzVnzIeC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qxcJhB8l1tX_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}